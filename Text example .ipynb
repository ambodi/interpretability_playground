{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import sklearn.ensemble\n",
    "import sklearn.metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import copy\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)\n",
    "class_names = ['atheism', 'christian']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False, token_pattern=r\"\\b\\w+\\b\")\n",
    "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
    "test_vectors = vectorizer.transform(newsgroups_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lreg = LogisticRegression(random_state=0, solver='lbfgs')\n",
    "lreg.fit(train_vectors, newsgroups_train.target)\n",
    "\n",
    "nbayes = MultinomialNB()\n",
    "nbayes.fit(train_vectors, newsgroups_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9205607476635513\n",
      "0.8816964285714286\n"
     ]
    }
   ],
   "source": [
    "pred_lreg = lreg.predict(test_vectors)\n",
    "print(sklearn.metrics.f1_score(newsgroups_test.target, pred_lreg, average='binary'))\n",
    "\n",
    "pred_nbayes = nbayes.predict(test_vectors)\n",
    "print(sklearn.metrics.f1_score(newsgroups_test.target, pred_nbayes, average='binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_nbayes_params = nbayes.coef_[0]\n",
    "global_lreg_params = lreg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_params_nbayes = np.abs(global_nbayes_params).argsort()[-10:][::-1]\n",
    "selected_params_nbayes_values = global_nbayes_params[selected_params_nbayes]\n",
    "\n",
    "selected_params_lreg = np.abs(global_lreg_params).argsort()[-10:][::-1]\n",
    "selected_params_lreg_values = global_lreg_params[selected_params_lreg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_names_nbayes = []\n",
    "selected_feature_names_lreg = []\n",
    "for sel_p_val in selected_params_nbayes:\n",
    "    selected_feature_names_nbayes.append(list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(sel_p_val)])  # Prints george\n",
    "    \n",
    "selected_feature_names_lreg = []\n",
    "for sel_p_val in selected_params_lreg:\n",
    "    selected_feature_names_lreg.append(list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(sel_p_val)])  # Prints george"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SP-LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Naive Bayes weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 83\n",
    "local_gt = train_vectors[idx].nonzero()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_weights_nbayes = np.abs(global_nbayes_params[local_gt]).argsort()[-10:][::-1]\n",
    "local_weights_lreg = np.abs(global_lreg_params[local_gt]).argsort()[-10:][::-1]\n",
    "\n",
    "selected_local_feature_names_nbayes = []\n",
    "selected_local_feature_names_lreg = []\n",
    "\n",
    "for sel_p_val in local_weights_nbayes:\n",
    "    selected_local_feature_names_nbayes.append(list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(sel_p_val)])  # Prints george\n",
    "\n",
    "for sel_p_val in local_weights_lreg:\n",
    "    selected_local_feature_names_lreg.append(list(vectorizer.vocabulary_.keys())[list(vectorizer.vocabulary_.values()).index(sel_p_val)])  # Prints george"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIME weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "from lime import lime_text\n",
    "from sklearn.pipeline import make_pipeline\n",
    "c_lreg = make_pipeline(vectorizer, lreg)\n",
    "c_nbayes = make_pipeline(vectorizer, nbayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document id: 83\n",
      "Probability(christian) = 0.8429648336399032\n",
      "True class: christian\n"
     ]
    }
   ],
   "source": [
    "explained_class = 1\n",
    "exp_lreg = explainer.explain_instance(newsgroups_train.data[idx], c_lreg.predict_proba, num_features=train_vectors.shape[1], labels=(explained_class, ))\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(christian) =', c_lreg.predict_proba([newsgroups_train.data[idx]])[0,1])\n",
    "print('True class: %s' % class_names[newsgroups_train.target[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document id: 83\n",
      "Probability(christian) = 0.9703013530527917\n",
      "True class: christian\n"
     ]
    }
   ],
   "source": [
    "explained_class = 1\n",
    "exp_nbayes = explainer.explain_instance(newsgroups_train.data[idx], c_nbayes.predict_proba, num_features=10, labels=(explained_class, ))\n",
    "print('Document id: %d' % idx)\n",
    "print('Probability(christian) =', c_nbayes.predict_proba([newsgroups_train.data[idx]])[0,1])\n",
    "print('True class: %s' % class_names[newsgroups_train.target[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_lime_nbayes = np.zeros((1, train_vectors.shape[1]))\n",
    "selected_features_lime_lreg = np.zeros((1, train_vectors.shape[1]))\n",
    "\n",
    "for e in exp_lreg.as_list():\n",
    "    selected_features_lime_lreg[:, vectorizer.vocabulary_[e[0]]] = e[1]\n",
    "\n",
    "for e in exp_nbayes.as_list():\n",
    "    selected_features_lime_nbayes[:, vectorizer.vocabulary_[e[0]]] = e[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KernelShap Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_train = np.median(train_vectors.toarray(), axis=0).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07d7392abcb4c31bf2d09e0739e78c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1df8f6c0e6548d28854dc3f408f64af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "l1_reg=\"auto\" is deprecated and in the next version (v0.29) the behavior will change from a conditional use of AIC to simply \"num_features(10)\"!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lreg_lambda = lambda x: lreg.predict_proba(x)[:, explained_class]\n",
    "nbayes_lambda = lambda x: nbayes.predict_proba(x)[:, explained_class]\n",
    "\n",
    "shap_explainer_nbayes = shap.KernelExplainer(nbayes_lambda, median_train)\n",
    "shap_values_nbayes = shap_explainer_nbayes.shap_values(train_vectors[idx], nsamples=1000)\n",
    "\n",
    "shap_explainer_lreg = shap.KernelExplainer(lreg_lambda, median_train)\n",
    "shap_values_lreg = shap_explainer_lreg.shap_values(train_vectors[idx], nsamples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.08013141]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(shap_values_lreg, selected_features_lime_lreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23098,)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_lime_lreg[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicand = copy.copy(test_vectors[idx].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "intervals = pd.qcut(range(100), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Interval(74.25, 99.0, closed='right')"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intervals[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_replacement(explicand, x_train, selected_features, model, explained_class):\n",
    "    result = 0\n",
    "    for j in range(selected_features.shape[0]):\n",
    "        explicand_copy = copy.copy(explicand)\n",
    "        explicand_f_val = explicand_copy[:, j][0]\n",
    "        feature_values = train_vectors[:, j].toarray().flatten()\n",
    "        bin_count, bin_edge = np.histogram(feature_values, bins=4)\n",
    "        \n",
    "        for i in range(0, len(bin_edge) - 1):\n",
    "            if explicand_f_val >= bin_edge[i] and  explicand_f_val < bin_edge[i+1]:\n",
    "                inst_in_interval = np.argwhere(np.logical_and(feature_values>=bin_edge[i], feature_values<bin_edge[i+1])).flatten()\n",
    "                bin_idx = i\n",
    "                \n",
    "                if len(inst_in_interval) == 0:\n",
    "                    bin_avg = bin_edge[i]\n",
    "                else:\n",
    "                    bin_avg = np.median(feature_values[inst_in_interval])\n",
    "\n",
    "        prior = bin_count[bin_idx] / len(feature_values)\n",
    "        explicand_copy[:, j] = bin_avg\n",
    "        \n",
    "        new_pred = model.predict_proba(explicand_copy)[0][explained_class]\n",
    "        \n",
    "        result += new_pred * prior\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pred_lreg = lreg.predict_proba(explicand)[0][explained_class]\n",
    "base_pred_nbayes = nbayes.predict_proba(explicand)[0][explained_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_pred_method_1_lreg_lime = predict_replacement(explicand, train_vectors, selected_features_lime_lreg.flatten(), lreg, explained_class)\n",
    "new_pred_method_1_nbayes_lime = predict_replacement(explicand, train_vectors, selected_features_lime_nbayes.flatten(), lreg, explained_class)\n",
    "new_pred_method_1_lreg_shap = predict_replacement(explicand, train_vectors, shap_values_lreg, nbayes, explained_class)\n",
    "new_pred_method_1_nbayes_shap = predict_replacement(explicand, train_vectors, shap_values_nbayes, nbayes, explained_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-10556.509614889284, 0.0009189599462474662)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(base_pred_lreg - new_pred_method_1_lreg_lime), (base_pred_lreg - new_pred_method_1_lreg_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicand_copy = copy.copy(explicand)\n",
    "\n",
    "for i in range(0, selected_features_lime_lreg.shape[1]):\n",
    "    explicand_copy[:, i] = np.mean(train_vectors[:, i]) \n",
    "\n",
    "new_pred_method_2_lreg_lime = lreg.predict_proba(explicand_copy)[0][explained_class]\n",
    "\n",
    "explicand_copy = copy.copy(explicand)\n",
    "\n",
    "for i in range(0, selected_features_lime_nbayes.shape[1]):\n",
    "    explicand_copy[:, i] = np.mean(train_vectors[:, i]) \n",
    "\n",
    "new_pred_method_2_lreg_lime = lreg.predict_proba(explicand_copy)[0][explained_class]\n",
    "\n",
    "\n",
    "explicand_copy = copy.copy(explicand)\n",
    "\n",
    "for i in range(0, selected_features_lime_lreg.shape[1]):\n",
    "    explicand_copy[:, i] = np.mean(train_vectors[:, i]) \n",
    "\n",
    "new_pred_method_2_lreg_lime = lreg.predict_proba(explicand_copy)[0][explained_class]\n",
    "\n",
    "explicand_copy = copy.copy(explicand)\n",
    "\n",
    "for i in range(0, selected_features_lime_lreg.shape[1]):\n",
    "    explicand_copy[:, i] = np.mean(train_vectors[:, i]) \n",
    "\n",
    "new_pred_method_2_lreg_lime = lreg.predict_proba(explicand_copy)[0][explained_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4300836130356512, -0.15239361205791208)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(base_pred - new_pred_method_1), (base_pred - new_pred_method_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_count, bin_edge = np.histogram(feature_values, bins='scott')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(bin_edge)):\n",
    "    if explicand_f_val > bin_edge[i] and  explicand_f_val<bin_edge[i+1]:\n",
    "        bin_idx = i\n",
    "        bin_avg = np.mean([bin_edge[i], bin_edge[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = bin_count[bin_idx] / len(feature_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0018535681186283596"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "explicand[:, selected_features_lime[0]] = bin_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbayes.predict(explicand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4103"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_lime[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 23035)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explicand.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TF GPU)",
   "language": "python",
   "name": "tf-pt-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
